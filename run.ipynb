{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# The DPLL Algorithm\n",
    "Leo Ware"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is my implementation of the DPLL algorithm, which is a heuristic algorithm for solving the general SAT problem.\n",
    "This implementation includes a nice Literal class for definition knowledgebases (KBs) and a function that implements the\n",
    "DPLL algorithm using different levels of heuristics according to a setting.\n",
    "\n",
    "First we can import the algorithm from the main file:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from main import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we can create an example knowledgebase and run the algorithm on it.\n",
    "We can get away with such a sparse representation because we know this is a propositional logic knowledgebase in\n",
    "conjunctive normal form. That means that each of the letters represents a logical sentence that can be true or false.\n",
    "Each set represents a disjunction---aka we a claiming that one of the sentences is true. And, the list represents a\n",
    "conjunction. We are saying that all of the disjunctions are true."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some literals\n",
    "A = Literal('A')\n",
    "B = Literal('B')\n",
    "C = Literal('C')\n",
    "D = Literal('D')\n",
    "E = Literal('E')\n",
    "F = Literal('F')\n",
    "\n",
    "# the KB from R&N\n",
    "KB = [\n",
    "    {-A, B, E},\n",
    "    {-B, A},\n",
    "    {-E, A},\n",
    "    {-E, D},\n",
    "    {-C, -F, -B},\n",
    "    {-E, B},\n",
    "    {-B, F},\n",
    "    {-B, C}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The algorithm will try to find an assignment such that the knowledgebase itself is true. This will look like a\n",
    "dictionary mapping from literals to booleans. This is known as the general SAT problem. This problem is NP-Complete,\n",
    "meaning that there is no known algorithm that can reliably solve it in less than exponential time. However, most\n",
    "(random) instances can be solved quite quickly by using efficient heuristics. Obviously, this example is small enough\n",
    "that it doesn't matter."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# run the algorithm\n",
    "dpll_satisfiable(KB)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(True,\n {Literal(name='B', sign=True): False,\n  Literal(name='A', sign=True): False,\n  Literal(name='D', sign=True): True,\n  Literal(name='E', sign=True): False},\n [Literal(name='B', sign=False),\n  Literal(name='C', sign=True),\n  Literal(name='A', sign=True),\n  Literal(name='F', sign=False),\n  Literal(name='A', sign=True),\n  Literal(name='E', sign=True),\n  Literal(name='D', sign=True),\n  Literal(name='E', sign=False)])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function returns three things: a boolean indicating whether the KB was successfully satisfied, an assignment, and a\n",
    "symbol trace. The assignment means that if you substitute each literal for the corresponding boolean, then the KB will\n",
    "be satisfied. An assignment like this is called a model.\n",
    "\n",
    "The trace shows which literals the algorithm visited while constructing this assignment. This is\n",
    "interesting because most of the cost of the algorithm comes from how many literals it visits, so we can compare\n",
    "different heuristics based on how many they visit. By default, the function runs with no heuristics---it just does depth\n",
    "first search on possible assignments. This is tractable for such a small KB, but we can see that it made a fair\n",
    "number of mistakes and had to backtrack multiple times."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heuristic level: 0\n",
      "trace length: 8\n",
      "trace [Literal(name='B', sign=False), Literal(name='C', sign=True), Literal(name='A', sign=True), Literal(name='F', sign=False), Literal(name='A', sign=True), Literal(name='E', sign=True), Literal(name='D', sign=True), Literal(name='E', sign=False)]\n",
      "\n",
      "heuristic level: 1\n",
      "trace length: 6\n",
      "trace [Literal(name='B', sign=False), Literal(name='A', sign=True), Literal(name='C', sign=False), Literal(name='F', sign=False), Literal(name='E', sign=False), Literal(name='A', sign=False)]\n",
      "\n",
      "heuristic level: 2\n",
      "trace length: 7\n",
      "trace [Literal(name='D', sign=True), Literal(name='B', sign=False), Literal(name='A', sign=True), Literal(name='C', sign=True), Literal(name='F', sign=False), Literal(name='E', sign=False), Literal(name='A', sign=False)]\n",
      "\n",
      "heuristic level: 3\n",
      "trace length: 7\n",
      "trace [Literal(name='D', sign=True), Literal(name='B', sign=False), Literal(name='A', sign=True), Literal(name='C', sign=True), Literal(name='F', sign=False), Literal(name='E', sign=False), Literal(name='A', sign=False)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with better heuristics\n",
    "for h_lvl in range(4):\n",
    "    print(\"heuristic level:\", h_lvl)\n",
    "    _, _, trace = dpll_satisfiable(KB, heuristic_level=h_lvl)\n",
    "    print(\"trace length:\", len(trace))\n",
    "    print(\"trace\", trace)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the algorithm doing here? Well, at `h_lvl=0`, the algorithm was doing dfs. Basically, it would keep guessing\n",
    "until it got a model that satisfied the KB. At higher levels, it employs smarter strategies.\n",
    "\n",
    "- At `h_lvl=1`, the algorithm employs the degree heuristic. It substitutes for the Literal that appears most often. This\n",
    "means that bad ideas die quickly. The more often a variable appears, the more likely it has to take a specific value. So,\n",
    "by guessing on the most frequent first, we avoid going down paths that are doomed to fail.\n",
    "- At `h_lvl=2`, the algorithm uses two heuristics which allows it to make substitutions with absolute certainty, instead\n",
    "of just guessing. If a variable appears only negated or only unnegated, then it can simply set it to be true (if\n",
    "unnegated) or false (if negated). Additionally, if a variable appears on its own, then it must be true (if unnegated) or\n",
    "false (if negated). By making these free substitutions, the algorithm saves on a lot of guessing.\n",
    "- At `h_lvl=3`, the algorithm combines these. It looks at all the literals nominated by the level 2 heuristic and picks\n",
    "the one that occurs the most times.\n",
    "\n",
    "We can see that in this instance, the cheapest heuristic actually performed best. However, all three heuristic\n",
    "algorithms outperformed brute force, and for larger problems though, you\n",
    "would definitely want to be running with all three."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}